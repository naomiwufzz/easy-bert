目录
1. [概览](#1-概览)
2. [DataParallel](#2-dataparallel)
   - [数据并行](#21-数据并行)
   - [负载不均衡问题](#22-负载不均衡问题)
3. [DistributedDataParallel](#3-distributeddataparallel)


## 1. 概览
模型的**并行训练**一般包含两种：

1. **单机多卡并行**（`nn.DataParallel`）；
   - 比较简单、使用范围较广
2. **多机多卡并行**（`nn.parallel.DistributedDataParallel`）
   - 较复杂，跨机器网络传输，易出问题（场景：大规模预训练）

## 2. DataParallel

### 2.1 数据并行
DataParallel翻译为**数据并行**，原理如图：

<img height="200" src="images/data-parallel.png"/>

上面**过程**如下：
- 每块GPU和显存分别独立维护一套完整的模型参数；
- 给定一个batch，**将batch划分为2份，分别送入不同的gpu**；
- 每个gpu**根据自己的batch子集和模型参数**，计算本地梯度；
- 将所有gpu的**本地梯度相加**，得到当前的batch总梯度；
- 使用batch总梯度，分别更新不同gpu上的模型参数；

**注意**：
- 参数更新时，每块gpu上的模型参数都应该是一致的；

### 2.2 负载不均衡问题
DataParallel下的**主gpu（gpu0）承担了额外的汇总调度**等，一般会使用更多的显存，如图：

<img height="200" src="images/data-parallel-lb-imbalanced.png"/>

一些情况下，不均衡的程度较为严重。 为了缓解此问题，可以使用 [BalancedDataParallel](https://github.com/Link-Li/Balanced-DataParallel) ， 它允许**为主gpu设置较少的batch子集**。

## 3. DistributedDataParallel
`nn.parallel.DistributedDataParallel`，翻译为分布式数据并行，原理如下图：

<img height="200" src="images/distributed-data-parallel.png"/>

- **每个GPU由一个独立的进程P控制**，**进程可能跨机器**；
- **不同进程间涉及数据、模型的同步**，较复杂，易出问题；
- 单机多gpu可以满足时, 不建议多机多gpu训练；
